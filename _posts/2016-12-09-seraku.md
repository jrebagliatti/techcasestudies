---
layout: post
title: "SERAKU turns to PaaS for greater scalability of its farming service"
author: "Hiroshi Ota"
author-link: "#"
#author-image: "{{ site.baseurl }}/images/authors/photo.jpg"
date: 2017-03-03
categories: [IoT]
color: "blue"
#image: "{{ site.baseurl }}/images/imagename.png" #should be ~350px tall
excerpt: SERAKU and Microsoft reconfigure an agricultural cloud using IoT Hub and Stream Analytics, aiming to facilitate a growing number of users and reduce operational costs.
language: [English]
verticals: ["Agriculture, Forestry & Fishing"]
geolocation: [Asia]
#permalink: /<page-title>.html
---

SERAKU provides an agricultural service, **[Midori Cloud](https://midori-cloud.net/)**, which measures and stores farm environmental data such as temperature, humidity, pressure, density of CO2, light strength, ground temperature, and soil moisture. Sensor configuration of each box is variable. This service also takes photos of farm products at uniform intervals, allowing the user to see the images compressed over time.  

Farmers find it very convenient to remotely see the growth of their crops. In addition, it is important to record environmental factors for the crops in order to increase revenue. This service is very popular and the number of users is increasing steadily. 

SERAKU wants to use platform as a service (PaaS) for easy scalability and to provide more flexible service extension. 

![Midori Cloud]({{ site.baseurl }}/images/seraku/seraku-iot-img_merritt_01.jpg)

This report describes the technology choices made and the learnings from SERAKU's hackfest with Microsoft.

### IoT technologies used

- Azure IoT SDK for C language on Raspbian
- Azure IoT Hub for connecting the Midori box and sending telemetry data and photographs 
- Azure Stream Analytics for processing and calculating statistical data from the sensors
- Azure DocumentDB for storing measured data from the sensors
- Azure Blob storage for storing photo (JPEG) files
- Azure Functions for calculating stored sensor data in DocumentDB as batch style

### Hackfest members 

|Company|Role|Names |
|--------|-------|-------|
|SERAKU |Device Side|   |
|    |Telemetry data processing|   |
|   |Photo Viewer business logic|   |
|   |Director|   |
|Microsoft Japan|Technical Evangelist  |[Hiroshi Ota](http://twitter.com/embedded_george) |

## Customer profile ##

[SERAKU](http://www.seraku.co.jp), founded in 1987, is a business support company that provides web marketing, system development of the mobile cloud, and IT infrastructure construction among its services. In addition to its branch offices in Japan, mainly in Tokyo, it has a subsidiary in Shenyang, China, with about 1,100 employees companywide.
 
## Problem statement ##

The current cloud service is run with infrastructure as a service (IaaS) hosted on Azure. But managing an increase in users of this service would be difficult and require more time for system management and maintenance.

SERAKU made the decision to select PaaS as its platform. Specifically, they want to resolve the following:

* Massive-scale ingestion of telemetry sensors. 
* Dealing with and storing large image files of crops. (Image file size is between 100 and 500 KB.)

In addition, they want the ability to configure the system to easily select sensor configuration according to customer need. Of course, a minimum requirement is that the new system does not degrade the performance of the graphical representation of telemetry stored data and video viewer. Searching and displaying should be finished so the user remains satisfied. 

## Solution and steps ##

### Architecture discussion

Microsoft met with SERAKU developers and provided an overview of Azure services related to IoT and recommended an architecture with the use of this [document](https://doc.co/mBQuqf). Next, SERAKU developers explained in detail the implementation of the current Midori Cloud. After that we discussed and decided on a new architectural overview.

### Hackfest

We held the two-day hackfest at the SERAKU office. During the hackfest, the SERAKU developers worked in parallel on the parts they were responsible for.　We carried out the following for each person in charge and proceeded with the work. 

- Talk about how to use the service and SDK.
- Provide sample of implementation.
- Discuss and decide how to solve problems that developers find. If necessary, provide new sample code/script.

![Hackfest picture]({{ site.baseurl }}/images/seraku/seraku-iot-hackfest.png)


After the hackfest, we dealt with questions and answers mainly by email.

## Learnings

To proceed smoothly with the work, it is helpful to provide training in basic use of services beforehand—for example, by using hands-on content. We provided some [learning content](https://doc.co/NsXXfD) via docs.com. This content is effective in providing basic knowledge and development skills. 

When the programming language is not a major one (C# or Node.js) used by the developers, few technical documents are available.  

![IoT Architecture Diagram]({{ site.baseurl }}/images/seraku/seraku-iot-iotarchitecture.png)


## Technical delivery ##

### Security

By using IoT Hub SAS token connection, only registered boxes can send messages and receive commands from the cloud. Even in the event of a stolen secret key, the operator can change the SAS token or delete registration by using IoT Hub management API. Communication between the box and IoT Hub uses SSL so that all messaging is encrypted.

The Midori box uploads the photograph file via IoT Hub blob upload API. Using this function makes it unnecessary for the device to have a secret key for blob access, minimizing security-related confidential information. 

The blob for storing photograph files is private so that unauthorized access is not possible. This security is important for the following reasons: 

- If anyone can see the photograph, especially of fruit, there is a risk of theft. In Japan, thefts of fruit just before harvest occur frequently. Therefore, it's important that only permitted users see the image files.
- Spoofing by image replacement by a third party is also a problem. Because of this, even legitimate users cannot modify images.

### Device 

![Midori Cloud Box]({{ site.baseurl }}/images/seraku/seraku-iot-midori_pro.png)


The Midori Cloud box includes Raspberry Pi and an application run on Raspbian. Connection to IoT Hub and sending telemetry logic are coded reference the [Azure IoT SDK](http://github.com/Azure/azure-iot-sdks) C language sample and use SDK base libraries. 

Once the measured data from the sensor is put into a buffer, it is sent at certain times to the IoT hub to reduce the communication line cost. Each sending packet size is 100 to 300 bytes.

At certain times, the box takes a photo and sends it to Azure Blog storage via the IoT hub file uploading feature.

### Storing and preprocessing telemetry using Stream Analytics job 

Basically, it is easy to calculate statistical data (average, minimum, maximum, and so on) by using Stream Analytics time window functions, but configuration of sensor devices is different for each customer. 

Telemetry data is sent by array style to IoT hub.

```json
{"Telemetry":[{"SensorType":"Temperature","SensorValue":27.253},{"SensorType":"Humidity","SensorValue":54.32},...]}
```

Because we hope to use the same query for various configurations of the sensor devices, we adopted the following query style.

```sql
WITH flat AS (
  SELECT boxId, Devicetime, ...,
  f.ArrayValue.Type AS SensorType,
  f.ArrayValue.Value as SensorValue
  FROM box as b Timestamp BY Devicetime
  CROSS APPLY GetArrayElements(b.Telemetry) as f
)
SELECT boxId, Devicetime, ...,
AVG(SensorValue) as temperatureAvg
INPUT statOutput FROM flat WHERE SensorType LIKE 'Temperature'
GROUP BY TumblingWindow(day, 1), boxId, ...
```

This query produced the following result.

```json
{"boxId":"xxx", "Devicetime":"2016/12/01T12:23:56Z",...,"temperaturAvg":17.93}
```

> The above script extracts the portion to calculate the average value, and the portion that outputs the original data is omitted.

Basic statistics calculation is processed by Stream Analytics and the results are stored in DocumentDB. Customers can see other, more complex statistical data from the stored telemetry data through existing services processing.

### Telemetry storage and connection to existing services

Preprocessed telemetry data from Stream Analytics is stored in DocumentDB. SERAKU adopted DocumentDB because this database service can store only JSON format, has strong query features, and its capacity is huge.

The following is a sample query.

```sql
SELECT TOP 10 * FROM c WHERE c.device.device_id = 330 AND (c.statictics.roundTimestamp BETWEEN %d AND %d) ORDER BY c.statictics.roundTimestamp DESC
```

We developed a function to capture DocumentDB. Stored data will be accessed from existing services.

### Photograph files stored in Blob storage

The photograph files taken by the Midori box are stored in an Azure Storage private blob. These files are used to show the changes in crop growth much like a flip book so that stored photograph files are able to be queried as fast as possible.

The blob service doesn't have a query feature, so we needed to think of a solution. We are trying the following mechanism:

* When a picture file is stored, the file name and some properties that are necessary for query are stored in Storage Table.
* By using the Storage Table query feature, we can search for a file set under specified conditions.

File selection rules are more complex than imagined because customers can specify files for use like a flip book that were taken during specific periods, such as only during sunrise. Whether this works well will be one of the validation items.
 
## Conclusion ##

The shift from IaaS to PaaS is expected to reduce the maintenance and operation costs against the increase in users, but the results will have to wait until after the service is in use.

From a development standpoint, it was an advantage to be able to start developing immediately through various mechanisms, including support of an SDK. 

One of our learnings from the project was that although there are many explanatory documents about each service, there are still some gaps in documentation guidance that need to be filled.

When trying to determine how to build the SAS token to use the private blog storage, a web search did not produce many useful results. In development at SERAKU, PHP is the main development language, but even with PHP we could not access the private blobs. Switching to a method using C# and Azure Storage SDK could be implemented, but SERAKU wanted to implement it with PHP if possible. 

In the case of Azure Functions, sometimes logs were not displayed at the time of execution by bind if it had been a long time since the last execution.

### Opportunities going forward

- SERAKU has provided Midori Cloud services for a long time, so it already has a lot of data consisting of many photographs of real crops and real environmental telemetry data.

- SERAKU will try to strengthen its existing predictive forecasting service by using Machine Learning/Deep Learning (ML/DL) based on new data with its own big data.

- SERAKU is also considering adoption of the latest IoT Hub feature *device twin* to make sensor box operation and maintenance easier.

